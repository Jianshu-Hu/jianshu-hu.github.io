<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jianshu Hu</title>

    <meta name="author" content="Jianshu Hu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="new_images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jianshu Hu
                </p>
                <p>I'm a PhD student at <a href="https://www.ji.sjtu.edu.cn/">UM-SJTU Joint Institute</a> in Shanghai,
                  working on sample-efficient and generalizable robot learning.
                  I am currently advised by <a href="https://people.csail.mit.edu/yban/index.html">Yutong Ban</a> and
                  <a href="https://weng.fr/">Paul Weng</a>. Before my PhD study, I finished my master degree in
                  <a href=https://www.grasp.upenn.edu/>Upenn GRASP</a>, advised by
                  <a href=https://dair.seas.upenn.edu/>Michael Posa</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:jianshuhu123@outlook.com">Email</a> &nbsp;/&nbsp;
<!--                  <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp;-->
<!--                  <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp;-->
                  <a href="https://scholar.google.com/citations?user=if-ScHUAAAAJ&hl=zh-CN&oi=ao">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Jianshu-Hu">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="new_images/personal_pic.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="new_images/personal_pic.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in reinforcement learning and robot manipulation. My current research focuses on
                  improving <strong>sample-efficiency</strong> and <strong>generalization ability</strong> of robot learning algorithms by
                  exploiting <strong>data augmentation</strong>, leveraging <strong>pre-trained models</strong>,
                  learning a <strong>dynamics model/world model</strong>.
                    Some papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="new_data/IROS2025/figure1.png" alt="b3do" width="160" style="border-style: none">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2503.01252">
      <span class="papertitle">Diffusion Stabilizer Policy for Automated Surgical Robot Manipulations
</span>
        </a>
        <br>
        <a href="https://scholar.google.com/citations?user=YLqZ5DUAAAAJ&hl=zh-CN&oi=ao">Chonlam Ho*</a>
         <strong>Jianshu Hu*</strong>,
        <a href="https://irmv.sjtu.edu.cn/wanghesheng_cn">Hesheng Wang</a>,
        <a href="https://carrend.github.io/">Qi Dou</a>,
        <a href="https://people.csail.mit.edu/yban/index.html">Yutong Ban</a>,

        <br>
        <em>Under Review</em>
        <br>
<!--        <a href="https://cat3d.github.io/">project page</a>-->
<!--        /-->
        <a href="https://arxiv.org/abs/2503.01252">arXiv</a>
        <p></p>
        <p>
          Aiming to extend the successes in solving manipulation tasks to the domain of surgical robotics, we propose a diffusion-based policy learning framework, called Diffusion Stabilizer Policy, which enables training with imperfect or even failed trajectories
        </p>
      </td>
    </tr>


      <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="new_data/MLJ2024/overview.png" alt="b3do" width="160" style="border-style: none">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2409.05433">
			<span class="papertitle">State-Novelty Guided Action Persistence in Deep Reinforcement Learning
</span>
        </a>
        <br>
         <strong>Jianshu Hu</strong>,
        <a href="https://weng.fr/">Paul Weng</a>,
        <a href="https://people.csail.mit.edu/yban/index.html">Yutong Ban</a>,

        <br>
        <em>Machine Learning Journal</em>
        <br>
<!--        <a href="https://cat3d.github.io/">project page</a>-->
<!--        /-->
        <a href="https://arxiv.org/abs/2409.05433">arXiv</a>
        <p></p>
        <p>
          In this paper, we propose a novel method to dynamically adjust the action persistence based on the current exploration status of the state space.
        </p>
      </td>
    </tr>


    <tr bgcolor="#ffffd0">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="new_data/ICLR2024/method.png" alt="b3do" width="160" style="border-style: none">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2402.12181">
			<span class="papertitle">Revisiting Data Augmentation in Deep Reinforcement Learning
</span>
        </a>
        <br>
		         <strong>Jianshu Hu</strong>,
        Yunpeng Jiang,
        <a href="https://weng.fr/">Paul Weng</a>,

        <br>
        <em>ICLR</em>, 2024
        <br>
<!--        <a href="https://cat3d.github.io/">project page</a>-->
<!--        /-->
        <a href="https://arxiv.org/abs/2402.12181">arXiv</a>
        <p></p>
        <p>
			We make recommendations on how to exploit data augmentation in image-based DRL in a more principled way.
          And we include a novel regularization term called tangent prop in RL training.
        </p>
      </td>
    </tr>


    <tr >
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="new_data/CoRL2022/method.png" alt="b3do" width="160" style="border-style: none">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://proceedings.mlr.press/v205/hu23a/hu23a.pdf">
			<span class="papertitle">Solving Complex Manipulation Tasks with Model-Assisted Model-Free Reinforcement Learning
</span>
        </a>
        <br>
		         <strong>Jianshu Hu</strong>,
        <a href="https://weng.fr/">Paul Weng</a>,

        <br>
        <em>CoRL</em>, 2022
        <br>
<!--        <a href="https://cat3d.github.io/">project page</a>-->
<!--        /-->
        <a href="https://www.semanticscholar.org/paper/Solving-Complex-Manipulation-Tasks-with-Model-Free-Hu-Weng/39ae24156b94a9ef91b4208c709a3c744896f611">paper link</a>
        <p></p>
        <p>
          A novel deep reinforcement learning approach for improving the sample efÔ¨Åciency of a model-free actor-critic method
          by using a learned model to encourage exploration.
        </p>
      </td>
    </tr>




      <tr >
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="new_data/T-RO2024/overview.png" alt="b3do" width="160" style="border-style: none">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://drive.google.com/file/d/1bNzSBdxGD7WsRkzVaCVodR_hA9iCPmBB/view">
			<span class="papertitle">Beyond Inverted Pendulums: Task-Optimal Simple Models of Legged Locomotion
</span>
        </a>
        <br>
        <a href="https://sites.google.com/view/ymchen/">Yu-Ming Chen</a>,
		         <strong>Jianshu Hu</strong>,
        <a href=https://dair.seas.upenn.edu/>Michael Posa,</a>,

        <br>
        <em>T-RO</em>
        <br>
<!--        <a href="https://cat3d.github.io/">project page</a>-->
<!--        /-->
        <a href="https://arxiv.org/abs/2301.02075">arXiv</a>
        <p></p>
        <p>
          We propose a model optimization algorithm that automatically synthesizes reduced-order models.
        </p>
      </td>
    </tr>


	



          </tbody></table>

          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="new_images/misc_small.jpg"></td>
              <td width="75%" valign="center">
                Reviewer, ICLR 2025
                <br>
                Reviewer, TNNLS
<!--                <br>-->
<!--                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>-->
              </td>
            </tr>

<!--            <tr>-->
<!--              <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--                <img src="images/cs188.jpg" alt="cs188">-->
<!--              </td>-->
<!--              <td width="75%" valign="center">-->
<!--                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>-->
<!--                <br>-->
<!--                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>-->
<!--                <br>-->
<!--                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>-->
<!--              </td>-->
<!--            </tr>-->
            

            
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  This website is build on this <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. Thanks to <a href="https://jonbarron.info/">Jon Barron.</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
